{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcitonality\n",
    "RNN is a class of nets that can predict the future. You can use it on sequences of arbitrary length, rather than fixed-sized inputs. So you can take sentences, documents or audios as input and make natural language precessing system like translation, speech to text or sentiment analysis(reading movie reviews and extracting the rate)\n",
    "\n",
    "You can also use RNN more creatively. Ask it to predit which are the most likely next notes in a melody and randomly pick one and play it. Then ask for the next note.\n",
    "\n",
    "# Simple Structure \n",
    "\n",
    "At each time step(frame), the recurrent neuron receives the inputs $x_{(t)}$ as well as the output from the previous time step,$y_{(t-1)}$\n",
    "$$ y_{(t)} =\\phi(x_{t}^T·w_x+y_{(t-1)}^T·w_y+b)$$\n",
    "\n",
    "Since the output of each neutron is a function of all inputs from previous time step, is has a form of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN from srcatch\n",
    "<img src='rnn.jpeg' width=300 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = tf.placeholder(tf.float32,[None,n_inputs])\n",
    "x1 = tf.placeholder(tf.float32,[None,n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "wx = tf.Variable(tf.random_normal(shape=[n_inputs,n_neurons],dtype=tf.float32))\n",
    "wy = tf.Variable(tf.random_normal(shape=[n_neuron,n_neurons],dtype=tf.float32))\n",
    "b = tf.Variable(tf.zeros([1,n_neurons],dtype=tf.float32)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = tf.tanh(tf.matmul(x0,wx)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = tf.tanh(tf.matmul(x1,wx)+tf.matmul(y0,wy)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_batch = np.array([[0,1,2],[3,4,5],[6,7,8],[9,0,1]])\n",
    "x1_batch = np.array([[9,8,7],[0,0,0],[6,5,4],[3,2,1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    y0_val,y1_val = sess.run([y0,y1],feed_dict={x0:x0_batch,x1:x1_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.817643  ,  0.99002373, -0.15017775, -0.99039215, -0.11675904],\n",
       "       [ 0.6172834 ,  0.9609914 ,  0.7072065 , -0.9999998 , -0.99672025],\n",
       "       [ 0.28355524,  0.8536817 ,  0.9574591 , -1.        , -0.9999932 ],\n",
       "       [-0.99999976, -1.        ,  0.9999995 , -0.9999973 , -1.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y0_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.99992687, -0.99934644,  0.9561947 , -1.        , -0.99999994],\n",
       "       [-0.9871589 ,  0.38692433,  0.3511038 , -0.2169611 , -0.7101225 ],\n",
       "       [-0.9988916 , -0.9993261 ,  0.99648106, -1.        , -0.99999815],\n",
       "       [-0.45749965, -0.99992913,  0.99873984, -0.99572533, -0.99713975]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,[None,n_steps,n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_seqs = tf.unstack(tf.transpose(x,perm=[1,0,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons,reuse=tf.AUTO_REUSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_seqs, state = tf.contrib.rnn.static_rnn(basic_cell,x_seqs,dtype=tf.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tf.transpose(tf.stack(output_seqs),perm=[1,0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_write = tf.summary.FileWriter('./rnn',tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch = np.array([\n",
    "    [[0,1,2],[9,8,7]],\n",
    "    [[3,4,5],[0,0,0]],\n",
    "    [[6,7,8],[6,5,4]],\n",
    "    [[9,0,1],[3,2,1]],    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    a = sess.run(x_seqs,feed_dict={x:x_batch})\n",
    "    output_val = outputs.eval(feed_dict={x:x_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.7056197 ,  0.74873227,  0.8752992 , -0.63706374,\n",
       "          0.4218465 ],\n",
       "        [ 0.9992527 ,  0.4342795 ,  1.        ,  0.8697232 ,\n",
       "          0.9767722 ]],\n",
       "\n",
       "       [[ 0.98771864,  0.9411917 ,  0.99985963, -0.65383077,\n",
       "          0.880359  ],\n",
       "        [-0.06295659, -0.7625946 ,  0.20157966,  0.7458381 ,\n",
       "         -0.17764854]],\n",
       "\n",
       "       [[ 0.99955773,  0.9873063 ,  0.99999976, -0.6699795 ,\n",
       "          0.9802841 ],\n",
       "        [ 0.98396033, -0.3915091 ,  0.99997765,  0.9398496 ,\n",
       "          0.83627725]],\n",
       "\n",
       "       [[-0.9044139 , -0.761997  ,  0.9998387 ,  0.83228326,\n",
       "         -0.9693899 ],\n",
       "        [ 0.2948277 , -0.49465013,  0.884769  ,  0.7809286 ,\n",
       "          0.80485773]]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_write.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, there are one time step. If we have larger number of time steps, the graph won't look good. And we may get out-of-memory problem since it must store all tensor values during the forward and backward pass. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There is a better solution: dynamic_rnn() \n",
    "There is no need to stack, unstack or transpose the input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,[None,n_steps,n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons,reuse=tf.AUTO_REUSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs,states = tf.nn.dynamic_rnn(basic_cell,x,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    outputs = sess.run(outputs,feed_dict={x:x_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.29133332, -0.40971285,  0.00474932,  0.7817908 ,\n",
       "         -0.17873375],\n",
       "        [-0.9999993 , -1.        , -0.9999995 ,  0.84270215,\n",
       "         -0.6409403 ]],\n",
       "\n",
       "       [[-0.9725871 , -0.99794674, -0.99233806,  0.9329037 ,\n",
       "         -0.49224204],\n",
       "        [-0.3418065 , -0.09544241, -0.3896178 , -0.8752379 ,\n",
       "          0.9042722 ]],\n",
       "\n",
       "       [[-0.999788  , -0.9999951 , -0.99997073,  0.9805134 ,\n",
       "         -0.7150079 ],\n",
       "        [-0.9999651 , -0.9999829 , -0.99998575, -0.84973294,\n",
       "          0.77066094]],\n",
       "\n",
       "       [[-0.99995595, -0.9998664 , -0.99997795, -0.99973094,\n",
       "          0.8243463 ],\n",
       "        [-0.99960214, -0.58785963, -0.99986583, -0.98049116,\n",
       "          0.8156727 ]]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable length input sequence\n",
    "If the input sequences of each instance is different, we have to clarity the number of sequence for each instance by setting the parameter  <code>sequence_length</code> when calling <code>python dynamic_rnn()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "n_steps = 2\n",
    "n_inputs = 1\n",
    "n_neurons = 1\n",
    "x_batch=[\n",
    "    [[2],[0]], # the dim of sequence in this should be the same with n_step. If there is no enough squence,pad with zero\n",
    "    [[1],[1]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,[None,n_steps,n_inputs])\n",
    "seq_length = tf.placeholder(tf.int32,[None])\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons,reuse=tf.AUTO_REUSE)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell,x,dtype=tf.float32,sequence_length=seq_length)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length_batch = np.array([1,2]) # each of the number in this array should be less or equal at n_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    outputs_val, states_val = sess.run([outputs,states],feed_dict={x:x_batch,seq_length:seq_length_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.9169307 ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[-0.6553968 ],\n",
       "        [-0.53586686]]], dtype=float32)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9570105]], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train RNN to MINST Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = os.getenv('HOME')\n",
    "data_path = home_path+'/program/ml/datasets/MNIST_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/zyan/program/ml/datasets/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/zyan/program/ml/datasets/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/zyan/program/ml/datasets/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/zyan/program/ml/datasets/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "n_inputs = 28\n",
    "n_steps = 28\n",
    "n_neurons = 100\n",
    "n_outputs = 10\n",
    "learning_rate = 0.001\n",
    "x = tf.placeholder(tf.float32,shape=[None,n_steps,n_inputs])\n",
    "y = tf.placeholder(tf.int32,[None])\n",
    "basic_cell = tf.nn.rnn_cell.BasicRNNCell(n_neurons,reuse=tf.AUTO_REUSE)\n",
    "#basic_cell = tf.nn.rnn_cell.DropoutWrapper(basic_cell,input_keep_prob=0.5)# add dropout\n",
    "\n",
    "outputs, stats = tf.nn.dynamic_rnn(basic_cell,inputs=x,dtype=tf.float32,initial_state=)\n",
    "logits = tf.layers.dense(stats,n_outputs)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits) \n",
    "loss = tf.reduce_mean(xentropy)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "correct = tf.nn.in_top_k(logits, y, 1) \n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32)) \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train_accuracy: 0.6696 test_accuracy: 0.6786\n",
      "1 train_accuracy: 0.7611455 test_accuracy: 0.7721\n",
      "2 train_accuracy: 0.8085273 test_accuracy: 0.8119\n",
      "3 train_accuracy: 0.83885455 test_accuracy: 0.8459\n",
      "4 train_accuracy: 0.85703635 test_accuracy: 0.8622\n",
      "5 train_accuracy: 0.86663634 test_accuracy: 0.8715\n",
      "6 train_accuracy: 0.8832909 test_accuracy: 0.8862\n",
      "7 train_accuracy: 0.8898909 test_accuracy: 0.8939\n",
      "8 train_accuracy: 0.8949818 test_accuracy: 0.8964\n",
      "9 train_accuracy: 0.90254545 test_accuracy: 0.9038\n",
      "10 train_accuracy: 0.9065091 test_accuracy: 0.9091\n",
      "11 train_accuracy: 0.9055091 test_accuracy: 0.9114\n",
      "12 train_accuracy: 0.9166727 test_accuracy: 0.9219\n",
      "13 train_accuracy: 0.9164 test_accuracy: 0.9198\n",
      "14 train_accuracy: 0.92163634 test_accuracy: 0.9218\n",
      "15 train_accuracy: 0.9197818 test_accuracy: 0.9227\n",
      "16 train_accuracy: 0.9263091 test_accuracy: 0.9295\n",
      "17 train_accuracy: 0.9206727 test_accuracy: 0.9198\n",
      "18 train_accuracy: 0.93087274 test_accuracy: 0.9292\n",
      "19 train_accuracy: 0.9304364 test_accuracy: 0.9317\n",
      "20 train_accuracy: 0.93374544 test_accuracy: 0.9369\n",
      "21 train_accuracy: 0.93154544 test_accuracy: 0.9352\n",
      "22 train_accuracy: 0.9348909 test_accuracy: 0.9338\n",
      "23 train_accuracy: 0.93865454 test_accuracy: 0.936\n",
      "24 train_accuracy: 0.93652725 test_accuracy: 0.9357\n",
      "25 train_accuracy: 0.9392545 test_accuracy: 0.9407\n",
      "26 train_accuracy: 0.9393455 test_accuracy: 0.9397\n",
      "27 train_accuracy: 0.94014543 test_accuracy: 0.9432\n",
      "28 train_accuracy: 0.9430182 test_accuracy: 0.9432\n",
      "29 train_accuracy: 0.945 test_accuracy: 0.9426\n",
      "30 train_accuracy: 0.9449273 test_accuracy: 0.9485\n",
      "31 train_accuracy: 0.94616365 test_accuracy: 0.9439\n",
      "32 train_accuracy: 0.9459818 test_accuracy: 0.948\n",
      "33 train_accuracy: 0.9471818 test_accuracy: 0.9484\n",
      "34 train_accuracy: 0.94732726 test_accuracy: 0.9475\n",
      "35 train_accuracy: 0.9481818 test_accuracy: 0.9491\n",
      "36 train_accuracy: 0.9475091 test_accuracy: 0.9466\n",
      "37 train_accuracy: 0.94054544 test_accuracy: 0.9456\n",
      "38 train_accuracy: 0.9488 test_accuracy: 0.9505\n",
      "39 train_accuracy: 0.9505091 test_accuracy: 0.9501\n",
      "40 train_accuracy: 0.95305455 test_accuracy: 0.9526\n",
      "41 train_accuracy: 0.9488182 test_accuracy: 0.9451\n",
      "42 train_accuracy: 0.9556 test_accuracy: 0.9554\n",
      "43 train_accuracy: 0.95534545 test_accuracy: 0.9529\n",
      "44 train_accuracy: 0.95705456 test_accuracy: 0.9547\n",
      "45 train_accuracy: 0.9556909 test_accuracy: 0.9556\n",
      "46 train_accuracy: 0.95696366 test_accuracy: 0.9555\n",
      "47 train_accuracy: 0.9550909 test_accuracy: 0.957\n",
      "48 train_accuracy: 0.95616364 test_accuracy: 0.9542\n",
      "49 train_accuracy: 0.9534909 test_accuracy: 0.9513\n",
      "50 train_accuracy: 0.95878184 test_accuracy: 0.9564\n",
      "51 train_accuracy: 0.95763636 test_accuracy: 0.956\n",
      "52 train_accuracy: 0.9552182 test_accuracy: 0.9525\n",
      "53 train_accuracy: 0.95756364 test_accuracy: 0.954\n",
      "54 train_accuracy: 0.9585818 test_accuracy: 0.9543\n",
      "55 train_accuracy: 0.95934546 test_accuracy: 0.9581\n",
      "56 train_accuracy: 0.959 test_accuracy: 0.9584\n",
      "57 train_accuracy: 0.9584182 test_accuracy: 0.9575\n",
      "58 train_accuracy: 0.9587455 test_accuracy: 0.9553\n",
      "59 train_accuracy: 0.9606909 test_accuracy: 0.9592\n",
      "60 train_accuracy: 0.95827276 test_accuracy: 0.9543\n",
      "61 train_accuracy: 0.9613091 test_accuracy: 0.9591\n",
      "62 train_accuracy: 0.96270907 test_accuracy: 0.9587\n",
      "63 train_accuracy: 0.9618545 test_accuracy: 0.9601\n",
      "64 train_accuracy: 0.9609454 test_accuracy: 0.9585\n",
      "65 train_accuracy: 0.96032727 test_accuracy: 0.9561\n",
      "66 train_accuracy: 0.95976365 test_accuracy: 0.958\n",
      "67 train_accuracy: 0.96198183 test_accuracy: 0.9581\n",
      "68 train_accuracy: 0.9612 test_accuracy: 0.9593\n",
      "69 train_accuracy: 0.96272725 test_accuracy: 0.9609\n",
      "70 train_accuracy: 0.9597273 test_accuracy: 0.9559\n",
      "71 train_accuracy: 0.96474546 test_accuracy: 0.963\n",
      "72 train_accuracy: 0.9647091 test_accuracy: 0.9638\n",
      "73 train_accuracy: 0.9622 test_accuracy: 0.9587\n",
      "74 train_accuracy: 0.9638182 test_accuracy: 0.9599\n",
      "75 train_accuracy: 0.9642364 test_accuracy: 0.9601\n",
      "76 train_accuracy: 0.9633091 test_accuracy: 0.9622\n",
      "77 train_accuracy: 0.96272725 test_accuracy: 0.9608\n",
      "78 train_accuracy: 0.9638182 test_accuracy: 0.9597\n",
      "79 train_accuracy: 0.9669091 test_accuracy: 0.964\n",
      "80 train_accuracy: 0.96343637 test_accuracy: 0.9607\n",
      "81 train_accuracy: 0.9658 test_accuracy: 0.9628\n",
      "82 train_accuracy: 0.96450907 test_accuracy: 0.9613\n",
      "83 train_accuracy: 0.9674 test_accuracy: 0.9625\n",
      "84 train_accuracy: 0.9640727 test_accuracy: 0.9641\n",
      "85 train_accuracy: 0.96294546 test_accuracy: 0.961\n",
      "86 train_accuracy: 0.9662182 test_accuracy: 0.9639\n",
      "87 train_accuracy: 0.9615091 test_accuracy: 0.9578\n",
      "88 train_accuracy: 0.96574545 test_accuracy: 0.9626\n",
      "89 train_accuracy: 0.9653818 test_accuracy: 0.963\n",
      "90 train_accuracy: 0.9672 test_accuracy: 0.9628\n",
      "91 train_accuracy: 0.9660909 test_accuracy: 0.9633\n",
      "92 train_accuracy: 0.9683818 test_accuracy: 0.9657\n",
      "93 train_accuracy: 0.9652727 test_accuracy: 0.9625\n",
      "94 train_accuracy: 0.968 test_accuracy: 0.9617\n",
      "95 train_accuracy: 0.9683091 test_accuracy: 0.9647\n",
      "96 train_accuracy: 0.9697091 test_accuracy: 0.9628\n",
      "97 train_accuracy: 0.96852726 test_accuracy: 0.9647\n",
      "98 train_accuracy: 0.96665454 test_accuracy: 0.9629\n",
      "99 train_accuracy: 0.9653091 test_accuracy: 0.9596\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        n_batch = data.train.num_examples//batch_size\n",
    "        for batch in range(n_batch):\n",
    "            x_batch,y_batch = data.train.next_batch(batch_size)\n",
    "            x_batch = x_batch.reshape((-1,n_steps,n_inputs))\n",
    "            sess.run(train_op,feed_dict={x:x_batch,y:y_batch})\n",
    "        accuracy_train = accuracy.eval(feed_dict={x:data.train.images.reshape((-1,n_steps,n_inputs)),y:data.train.labels})\n",
    "        accuracy_test = accuracy.eval(feed_dict={x:data.test.images.reshape((-1,n_steps,n_inputs)),y:data.test.labels})\n",
    "        print(epoch,'train_accuracy:',accuracy_train,'test_accuracy:',accuracy_test)\n",
    "    #outputs_eval = outputs.eval(feed_dict={x:x_batch[:10]})\n",
    "    #stats_eval = stats.eval(feed_dict={x:x_batch[:10]})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfkernel",
   "language": "python",
   "name": "tfkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

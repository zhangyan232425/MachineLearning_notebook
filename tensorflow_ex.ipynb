{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "## Normal equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing  = pd.read_csv('/Users/zyan/program/ml/datasets/housing/housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_target = housing['median_house_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = housing.drop(['median_house_value','ocean_proximity'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "m , n = housing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "       'total_bedrooms', 'population', 'households', 'median_income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_plus_bias  = np.c_[np.ones((m,1)),housing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.constant(housing_plus_bias,dtype=tf.float64,name='X')\n",
    "Y = tf.constant(housing_target.values.reshape(-1,1),dtype=tf.float64,name='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)),XT),Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = imputer.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_scaled = preprocessing.scale(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_scaled_plus_bias = np.c_[np.ones((m,1)),housing_scaled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.constant(housing_scaled_plus_bias,dtype=tf.float32,name='X')\n",
    "Y = tf.constant(housing_target.values.reshape(-1,1),dtype=tf.float32,name='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0,-1.0),name='theta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = tf.matmul(X,theta,name = 'predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = Y-Y_pred\n",
    "mse = tf.reduce_mean(tf.square(error),name='mse')\n",
    "gradients = 2/m*tf.matmul(tf.transpose(X),error)\n",
    "training_op=tf.assign(theta,theta-learning_rate*gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE=  56105464000.0\n",
      "Epoch 100 MSE=  181823030000000.0\n",
      "Epoch 200 MSE=  6.002448e+20\n",
      "Epoch 300 MSE=  2.0112107e+27\n",
      "Epoch 400 MSE=  6.738874e+33\n",
      "Epoch 500 MSE=  inf\n",
      "Epoch 600 MSE=  inf\n",
      "Epoch 700 MSE=  inf\n",
      "Epoch 800 MSE=  inf\n",
      "Epoch 900 MSE=  inf\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch%100 ==0:\n",
    "            print('Epoch',epoch,'MSE= ',mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**You don't have to hard caculate gradient by yourself. Tensorflow can do it for you.**\n",
    "```\n",
    "gradients = tf.gradients(mse,[theta])[0]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(1,dtype='float32')\n",
    "y=tf.constant(2,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x+2*y\n",
    "gradients = tf.gradients(z,[y,x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "init1 = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(gradients[1].eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then you can update z by its gradients**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Furthermore, you can choose optimizer to compute the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "# choose other different optimizer : optimizer = tf.train.MomentumOptimizer(...)\n",
    "training_op = optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed data using mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,shape=(None,n+1),name='X')# shape = None means any length of the dimention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = tf.placeholder(tf.float32,shape=(None,1),name='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =100\n",
    "n_batches = int(np.ceil(m/batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then fetch mini-batch one by one and feed to the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch(epoch,batch_index,batch_size):\n",
    "    x_batch = housing_scaled_plus_bias[batch_index*batch_size:batch_index*batch_size+batch_size]\n",
    "    y_batch = housing_target[batch_index*batch_size:batch_index*batch_size+batch_size]\n",
    "    return x_batch,y_batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            x_batch,y_batch = fetch_batch(epoch,batch_index,batch_size)\n",
    "            sess.run(training_op,feed_dict={X:x_batch,Y:y_batch.values.reshape(-1,1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and restoring models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving\n",
    "Just create a Saver node at the end of the construction and in the execution phase, call its save() method whenever you want to save the model\n",
    "```\n",
    "...\n",
    "...\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "...\n",
    "save_path = saver.save(sess,'/tmp/my_model.ckpt')\n",
    "...\n",
    "...\n",
    "save_path = saver.save(sess,'/tmp/my_model_final.ckpt')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restoring\n",
    "\n",
    "your create a Saver at the end of the construction and at the begining of execution,instead of initializing the variables using the init node , you can call the restore() method of the Saver\n",
    "```\n",
    "...\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "saver.restore(sess,'/tmp/my_model_final.ckpt')\n",
    "...\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "Use a different log directory every time you run your program so you won't mess up the tensor board when it load the log file. So you can include date in log directory name.<span style=\"color:red\">Aboid logging training stats at every training step, as this would slow down training.</span>\n",
    "\n",
    "**At the begining of the program**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now().strftime('%Y%m%d%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = 'tf_logs'\n",
    "logdir = '{}/run-{}'.format(root_logdir,now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then add the following at the very end of construction \n",
    "```\n",
    "mse_summary = tf.summary.scalar('MSE',mse) # this node will evaluate the MSE value and write it to a log string called summay\n",
    "file_write = tf.summary.FileWrite(logdir,tf.get_default_graph()) \n",
    "```\n",
    "Update the execution to evaluate mse_summary regularly during the training.\n",
    "\n",
    "```\n",
    "...\n",
    "for bath_index in range(n_bathes):\n",
    "    x_batch,y_batch...\n",
    "    if batch_index %10==0:\n",
    "        summary_str = mse_summary.eval(feed_dic={X:x_batch,Y:y_batch})\n",
    "        step = epoch*n_batch+batch_index\n",
    "        file_write.add_summary(summary_str,step)\n",
    "    sess.run(training_op,feed_dict={X:x_batch,Y:y_batch})\n",
    "...\n",
    "```\n",
    "\n",
    "At the end of program, close the FileWriter\n",
    "\n",
    "```\n",
    "file_write.colse()\n",
    "```\n",
    "To start TensorBoard web server point to the root log directory\n",
    "```\n",
    "tensorboard --logdir tf_logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss') as scope:\n",
    "    error = Y_pred-Y\n",
    "    mse = tf.reduce_mean(tf.square(error),name='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_1/sub\n"
     ]
    }
   ],
   "source": [
    "print(error.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_1/mse\n"
     ]
    }
   ],
   "source": [
    "print(mse.op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing Variable\n",
    "use get_variable when you reuse the variable you have to set scope's reuse = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('relu'):\n",
    "    threshold = tf.get_variable('threshold',shape=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('relu'):\n",
    "    threshold = tf.get_variable('threshol',shape=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfkernel",
   "language": "python",
   "name": "tfkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
